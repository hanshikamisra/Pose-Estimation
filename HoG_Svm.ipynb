{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Dataset Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MPII dataset...\n",
      "Loading annotations from mpii_human_pose_v1_u12_1.mat\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 364\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# 1. Load MPII dataset\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading MPII dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 364\u001b[0m mpii_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_mpii_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmpii_human_pose_v1_u12_1.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# Check if we got any data\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mpii_data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m, in \u001b[0;36mload_mpii_dataset\u001b[1;34m(annot_file, img_dir)\u001b[0m\n\u001b[0;32m     20\u001b[0m annotations \u001b[38;5;241m=\u001b[39m annotations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRELEASE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     21\u001b[0m img_names \u001b[38;5;241m=\u001b[39m annotations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannolist\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 22\u001b[0m joint_annotations \u001b[38;5;241m=\u001b[39m \u001b[43mannotations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mannolist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     23\u001b[0m is_train \u001b[38;5;241m=\u001b[39m annotations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_train\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     25\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Load MPII dataset annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Load MPII dataset annotations\n",
    "def load_mpii_dataset(annot_file, img_dir):\n",
    "    print(f\"Loading annotations from {annot_file}\")\n",
    "    annotations = loadmat(annot_file)\n",
    "    \n",
    "    # Extract relevant data\n",
    "    annotations = annotations['RELEASE']\n",
    "    img_names = annotations['annolist'][0, 0][0]\n",
    "    joint_annotations = annotations['annolist'][0, 0][1]\n",
    "    is_train = annotations['img_train'][0, 0][0]\n",
    "    \n",
    "    data = []\n",
    "    valid_count = 0\n",
    "    \n",
    "    for i in range(len(img_names)):\n",
    "        if is_train[i]:  # Only use training data\n",
    "            try:\n",
    "                img_name = str(img_names[i][0][0][0])\n",
    "                joints = joint_annotations[i][0][0]\n",
    "                \n",
    "                if len(joints) > 0 and 'x' in dir(joints[0][0]):\n",
    "                    joint_coords = []\n",
    "                    for j in range(joints.shape[0]):\n",
    "                        if joints[j][0].size > 0:\n",
    "                            x = float(joints[j][0]['x'][0, 0])\n",
    "                            y = float(joints[j][0]['y'][0, 0])\n",
    "                            joint_coords.append((x, y))\n",
    "                        else:\n",
    "                            joint_coords.append(None)\n",
    "                    \n",
    "                    img_path = os.path.join(img_dir, img_name)\n",
    "                    if os.path.exists(img_path):\n",
    "                        data.append({\n",
    "                            'img_path': img_path,\n",
    "                            'joints': joint_coords\n",
    "                        })\n",
    "                        valid_count += 1\n",
    "                        # Limit to a reasonable number for initial testing\n",
    "                        if valid_count >= 500:\n",
    "                            break\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    print(f\"Loaded {len(data)} valid annotations\")\n",
    "    return data\n",
    "\n",
    "# Preprocess data for HOG+SVM\n",
    "def preprocess_for_hog_svm(data):\n",
    "    processed_data = []\n",
    "    \n",
    "    for item in data:\n",
    "        img = cv2.imread(item['img_path'])\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        # Get bounding box from joints\n",
    "        valid_joints = [j for j in item['joints'] if j is not None]\n",
    "        if not valid_joints:\n",
    "            continue\n",
    "            \n",
    "        x_coords = [j[0] for j in valid_joints]\n",
    "        y_coords = [j[1] for j in valid_joints]\n",
    "        \n",
    "        # Get bounding box with padding\n",
    "        x_min, x_max = min(x_coords), max(x_coords)\n",
    "        y_min, y_max = min(y_coords), max(y_coords)\n",
    "        \n",
    "        # Add padding\n",
    "        width = max(1, x_max - x_min)  # Avoid division by zero\n",
    "        height = max(1, y_max - y_min)\n",
    "        padding_x = width * 0.2\n",
    "        padding_y = height * 0.2\n",
    "        \n",
    "        x_min = max(0, x_min - padding_x)\n",
    "        x_max = min(img.shape[1], x_max + padding_x)\n",
    "        y_min = max(0, y_min - padding_y)\n",
    "        y_max = min(img.shape[0], y_max + padding_y)\n",
    "        \n",
    "        # Crop person\n",
    "        person_img = img[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "        \n",
    "        # Resize for consistent HOG feature extraction\n",
    "        try:\n",
    "            resized_img = cv2.resize(person_img, (128, 256))\n",
    "            \n",
    "            # Store original joint coordinates relative to the cropped image\n",
    "            adjusted_joints = []\n",
    "            for joint in item['joints']:\n",
    "                if joint is not None:\n",
    "                    # Scale joint coordinates to the resized image\n",
    "                    adj_x = (joint[0] - x_min) * 128 / (x_max - x_min)\n",
    "                    adj_y = (joint[1] - y_min) * 256 / (y_max - y_min)\n",
    "                    adjusted_joints.append((adj_x, adj_y))\n",
    "                else:\n",
    "                    adjusted_joints.append(None)\n",
    "            \n",
    "            processed_data.append({\n",
    "                'image': resized_img,\n",
    "                'joints': adjusted_joints,\n",
    "                'original_path': item['img_path']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {item['img_path']}: {e}\")\n",
    "    \n",
    "    print(f\"Processed {len(processed_data)} images\")\n",
    "    return processed_data\n",
    "\n",
    "# Extract HOG features\n",
    "def extract_hog_features(processed_data):\n",
    "    # HOG parameters\n",
    "    win_size = (128, 256)\n",
    "    block_size = (16, 16)\n",
    "    block_stride = (8, 8)\n",
    "    cell_size = (8, 8)\n",
    "    nbins = 9\n",
    "    \n",
    "    # Initialize HOG descriptor\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for i, item in enumerate(processed_data):\n",
    "        print(f\"Extracting HOG features for image {i+1}/{len(processed_data)}...\", end=\"\\r\")\n",
    "        \n",
    "        img_gray = cv2.cvtColor(item['image'], cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Extract HOG features\n",
    "        hog_features = hog.compute(img_gray)\n",
    "        features.append(hog_features.flatten())\n",
    "        \n",
    "        # Format joints as labels\n",
    "        flat_joints = []\n",
    "        for joint in item['joints']:\n",
    "            if joint is not None:\n",
    "                flat_joints.extend([joint[0], joint[1]])\n",
    "            else:\n",
    "                flat_joints.extend([0, 0])  # Use 0,0 for missing joints\n",
    "        \n",
    "        labels.append(np.array(flat_joints))\n",
    "    \n",
    "    print(\"\\nFeature extraction complete!\")\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Train SVR models for each joint\n",
    "def train_joint_models(X_train, y_train, X_test, y_test, num_joints=16):\n",
    "    joint_models = []\n",
    "    joint_errors = []\n",
    "    \n",
    "    # Calculate the number of joints from the data\n",
    "    num_joints = y_train.shape[1] // 2\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train a separate model for each joint (x,y) coordinate\n",
    "    for i in range(num_joints):\n",
    "        print(f\"Training model for joint {i+1}/{num_joints}...\")\n",
    "        \n",
    "        # X-coordinate model\n",
    "        x_model = SVR(kernel='rbf', C=10, gamma='scale')\n",
    "        x_model.fit(X_train, y_train[:, i*2])\n",
    "        \n",
    "        # Y-coordinate model\n",
    "        y_model = SVR(kernel='rbf', C=10, gamma='scale')\n",
    "        y_model.fit(X_train, y_train[:, i*2+1])\n",
    "        \n",
    "        # Validate\n",
    "        x_pred = x_model.predict(X_test)\n",
    "        y_pred = y_model.predict(X_test)\n",
    "        \n",
    "        # Calculate error\n",
    "        x_mse = mean_squared_error(y_test[:, i*2], x_pred)\n",
    "        y_mse = mean_squared_error(y_test[:, i*2+1], y_pred)\n",
    "        \n",
    "        joint_models.append((x_model, y_model))\n",
    "        joint_errors.append((x_mse, y_mse))\n",
    "        \n",
    "        print(f\"  Joint {i+1} X MSE: {x_mse:.4f}, Y MSE: {y_mse:.4f}\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Training completed in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return joint_models, joint_errors\n",
    "\n",
    "# Evaluate and visualize results\n",
    "def evaluate_and_visualize(processed_data, joint_models, feature_scaler, num_samples=5):\n",
    "    # Choose random samples for visualization\n",
    "    sample_indices = np.random.choice(len(processed_data), min(num_samples, len(processed_data)), replace=False)\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        img = processed_data[idx]['image']\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Extract HOG features\n",
    "        hog = cv2.HOGDescriptor((128, 256), (16, 16), (8, 8), (8, 8), 9)\n",
    "        features = hog.compute(img_gray).flatten()\n",
    "        \n",
    "        # Scale features\n",
    "        features_scaled = feature_scaler.transform(features.reshape(1, -1))\n",
    "        \n",
    "        # Predict joint positions\n",
    "        predicted_joints = []\n",
    "        for x_model, y_model in joint_models:\n",
    "            x_pred = x_model.predict(features_scaled)[0]\n",
    "            y_pred = y_model.predict(features_scaled)[0]\n",
    "            predicted_joints.append((x_pred, y_pred))\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Original image with ground truth\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        for joint in processed_data[idx]['joints']:\n",
    "            if joint is not None:\n",
    "                plt.plot(joint[0], joint[1], 'go', markersize=5)\n",
    "        plt.title('Ground Truth')\n",
    "        \n",
    "        # Image with predictions\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        for joint in predicted_joints:\n",
    "            plt.plot(joint[0], joint[1], 'ro', markersize=5)\n",
    "        plt.title('Predictions')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Draw skeleton for better visualization\n",
    "        plt.figure(figsize=(8, 16))\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Draw predicted joints\n",
    "        for joint in predicted_joints:\n",
    "            plt.plot(joint[0], joint[1], 'ro', markersize=5)\n",
    "        \n",
    "        # Define skeleton connections - simplified MPII skeleton\n",
    "        # Adjust based on your joint ordering in MPII dataset\n",
    "        skeleton_pairs = [\n",
    "            (0, 1),  # head to neck\n",
    "            (1, 2),  # neck to right shoulder\n",
    "            (1, 5),  # neck to left shoulder\n",
    "            (2, 3),  # right shoulder to right elbow\n",
    "            (3, 4),  # right elbow to right wrist\n",
    "            (5, 6),  # left shoulder to left elbow\n",
    "            (6, 7),  # left elbow to left wrist\n",
    "            (1, 8),  # neck to hip\n",
    "            (8, 9),  # hip to right hip\n",
    "            (8, 12), # hip to left hip\n",
    "            (9, 10), # right hip to right knee\n",
    "            (10, 11), # right knee to right ankle\n",
    "            (12, 13), # left hip to left knee\n",
    "            (13, 14)  # left knee to left ankle\n",
    "        ]\n",
    "        \n",
    "        # Draw skeleton lines connecting joints\n",
    "        for pair in skeleton_pairs:\n",
    "            if pair[0] < len(predicted_joints) and pair[1] < len(predicted_joints):\n",
    "                plt.plot([predicted_joints[pair[0]][0], predicted_joints[pair[1]][0]],\n",
    "                         [predicted_joints[pair[0]][1], predicted_joints[pair[1]][1]], 'b-', linewidth=2)\n",
    "        \n",
    "        plt.title('Pose Skeleton')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Function to predict pose on new images\n",
    "def predict_pose(image_path, joint_models, feature_scaler):\n",
    "    # Load and preprocess image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not load image from {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Resize for consistent HOG extraction\n",
    "    img_resized = cv2.resize(img, (128, 256))\n",
    "    img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Extract HOG features\n",
    "    hog = cv2.HOGDescriptor((128, 256), (16, 16), (8, 8), (8, 8), 9)\n",
    "    features = hog.compute(img_gray).flatten()\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = feature_scaler.transform(features.reshape(1, -1))\n",
    "    \n",
    "    # Predict joint positions\n",
    "    predicted_joints = []\n",
    "    for x_model, y_model in joint_models:\n",
    "        x_pred = x_model.predict(features_scaled)[0]\n",
    "        y_pred = y_model.predict(features_scaled)[0]\n",
    "        predicted_joints.append((x_pred, y_pred))\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(8, 16))\n",
    "    plt.imshow(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Draw predicted joints\n",
    "    for joint in predicted_joints:\n",
    "        plt.plot(joint[0], joint[1], 'ro', markersize=5)\n",
    "    \n",
    "    # Draw skeleton lines connecting joints\n",
    "    skeleton_pairs = [\n",
    "        (0, 1),  # head to neck\n",
    "        (1, 2),  # neck to right shoulder\n",
    "        (1, 5),  # neck to left shoulder\n",
    "        (2, 3),  # right shoulder to right elbow\n",
    "        (3, 4),  # right elbow to right wrist\n",
    "        (5, 6),  # left shoulder to left elbow\n",
    "        (6, 7),  # left elbow to left wrist\n",
    "        (1, 8),  # neck to hip\n",
    "        (8, 9),  # hip to right hip\n",
    "        (8, 12), # hip to left hip\n",
    "        (9, 10), # right hip to right knee\n",
    "        (10, 11), # right knee to right ankle\n",
    "        (12, 13), # left hip to left knee\n",
    "        (13, 14)  # left knee to left ankle\n",
    "    ]\n",
    "    \n",
    "    for pair in skeleton_pairs:\n",
    "        if pair[0] < len(predicted_joints) and pair[1] < len(predicted_joints):\n",
    "            plt.plot([predicted_joints[pair[0]][0], predicted_joints[pair[1]][0]],\n",
    "                     [predicted_joints[pair[0]][1], predicted_joints[pair[1]][1]], 'b-', linewidth=2)\n",
    "    \n",
    "    plt.title('Pose Estimation')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_joints\n",
    "\n",
    "# Function to save models\n",
    "def save_models(joint_models, feature_scaler, filepath='hog_svm_pose_model.pkl'):\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'joint_models': joint_models,\n",
    "            'feature_scaler': feature_scaler\n",
    "        }, f)\n",
    "    print(f\"Models saved to {filepath}\")\n",
    "\n",
    "# Function to load models\n",
    "def load_models(filepath='hog_svm_pose_model.pkl'):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data['joint_models'], data['feature_scaler']\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    import pickle\n",
    "    \n",
    "    # 1. Load MPII dataset\n",
    "    print(\"Loading MPII dataset...\")\n",
    "    mpii_data = load_mpii_dataset('mpii_human_pose_v1_u12_1.mat', './') \n",
    "    \n",
    "    # Check if we got any data\n",
    "    if len(mpii_data) == 0:\n",
    "        print(\"No data loaded from MPII dataset. Check paths and file format.\")\n",
    "    else:\n",
    "        # 2. Preprocess data\n",
    "        print(\"\\nPreprocessing images...\")\n",
    "        processed_mpii = preprocess_for_hog_svm(mpii_data)\n",
    "        \n",
    "        # 3. Extract HOG features\n",
    "        print(\"\\nExtracting HOG features...\")\n",
    "        X, y = extract_hog_features(processed_mpii)\n",
    "        print(f\"Feature matrix shape: {X.shape}\")\n",
    "        print(f\"Labels matrix shape: {y.shape}\")\n",
    "        \n",
    "        # 4. Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # 5. Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # 6. Train models\n",
    "        print(\"\\nTraining SVM models...\")\n",
    "        joint_models, errors = train_joint_models(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "        \n",
    "        # 7. Save models\n",
    "        save_models(joint_models, scaler)\n",
    "        \n",
    "        # 8. Evaluate\n",
    "        print(\"\\nEvaluating models...\")\n",
    "        evaluate_and_visualize(processed_mpii, joint_models, scaler, num_samples=3)\n",
    "        \n",
    "        # 9. Test on specific image\n",
    "        print(\"\\nTesting on a new image...\")\n",
    "        test_img_path = processed_mpii[0]['original_path']  # Using first image as example\n",
    "        predict_pose(test_img_path, joint_models, scaler)\n",
    "\n",
    "# Preprocess data for HOG+SVM\n",
    "def preprocess_for_hog_svm(data):\n",
    "    processed_data = []\n",
    "    \n",
    "    for item in data:\n",
    "        img = cv2.imread(item['img_path'])\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        # Get bounding box from joints\n",
    "        valid_joints = [j for j in item['joints'] if j is not None]\n",
    "        if not valid_joints:\n",
    "            continue\n",
    "            \n",
    "        x_coords = [j[0] for j in valid_joints]\n",
    "        y_coords = [j[1] for j in valid_joints]\n",
    "        \n",
    "        # Get bounding box with padding\n",
    "        x_min, x_max = min(x_coords), max(x_coords)\n",
    "        y_min, y_max = min(y_coords), max(y_coords)\n",
    "        \n",
    "        # Add padding\n",
    "        width = max(1, x_max - x_min)  # Avoid division by zero\n",
    "        height = max(1, y_max - y_min)\n",
    "        padding_x = width * 0.2\n",
    "        padding_y = height * 0.2\n",
    "        \n",
    "        x_min = max(0, x_min - padding_x)\n",
    "        x_max = min(img.shape[1], x_max + padding_x)\n",
    "        y_min = max(0, y_min - padding_y)\n",
    "        y_max = min(img.shape[0], y_max + padding_y)\n",
    "        \n",
    "        # Crop person\n",
    "        person_img = img[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "        \n",
    "        # Resize for consistent HOG feature extraction\n",
    "        try:\n",
    "            resized_img = cv2.resize(person_img, (128, 256))\n",
    "            \n",
    "            # Store original joint coordinates relative to the cropped image\n",
    "            adjusted_joints = []\n",
    "            for joint in item['joints']:\n",
    "                if joint is not None:\n",
    "                    # Scale joint coordinates to the resized image\n",
    "                    adj_x = (joint[0] - x_min) * 128 / (x_max - x_min)\n",
    "                    adj_y = (joint[1] - y_min) * 256 / (y_max - y_min)\n",
    "                    adjusted_joints.append((adj_x, adj_y))\n",
    "                else:\n",
    "                    adjusted_joints.append(None)\n",
    "            \n",
    "            processed_data.append({\n",
    "                'image': resized_img,\n",
    "                'joints': adjusted_joints,\n",
    "                'original_path': item['img_path']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {item['img_path']}: {e}\")\n",
    "    \n",
    "    print(f\"Processed {len(processed_data)} images\")\n",
    "    return processed_data\n",
    "\n",
    "# Extract HOG features\n",
    "def extract_hog_features(processed_data):\n",
    "    # HOG parameters\n",
    "    win_size = (128, 256)\n",
    "    block_size = (16, 16)\n",
    "    block_stride = (8, 8)\n",
    "    cell_size = (8, 8)\n",
    "    nbins = 9\n",
    "    \n",
    "    # Initialize HOG descriptor\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for i, item in enumerate(processed_data):\n",
    "        print(f\"Extracting HOG features for image {i+1}/{len(processed_data)}...\", end=\"\\r\")\n",
    "        \n",
    "        img_gray = cv2.cvtColor(item['image'], cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Extract HOG features\n",
    "        hog_features = hog.compute(img_gray)\n",
    "        features.append(hog_features.flatten())\n",
    "        \n",
    "        # Format joints as labels\n",
    "        flat_joints = []\n",
    "        for joint in item['joints']:\n",
    "            if joint is not None:\n",
    "                flat_joints.extend([joint[0], joint[1]])\n",
    "            else:\n",
    "                flat_joints.extend([0, 0])  # Use 0,0 for missing joints\n",
    "        \n",
    "        labels.append(np.array(flat_joints))\n",
    "    \n",
    "    print(\"\\nFeature extraction complete!\")\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Train SVR models for each joint\n",
    "def train_joint_models(X_train, y_train, X_test, y_test, num_joints=16):\n",
    "    joint_models = []\n",
    "    joint_errors = []\n",
    "    \n",
    "    # Calculate the number of joints from the data\n",
    "    num_joints = y_train.shape[1] // 2\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train a separate model for each joint (x,y) coordinate\n",
    "    for i in range(num_joints):\n",
    "        print(f\"Training model for joint {i+1}/{num_joints}...\")\n",
    "        \n",
    "        # X-coordinate model\n",
    "        x_model = SVR(kernel='rbf', C=10, gamma='scale')\n",
    "        x_model.fit(X_train, y_train[:, i*2])\n",
    "        \n",
    "        # Y-coordinate model\n",
    "        y_model = SVR(kernel='rbf', C=10, gamma='scale')\n",
    "        y_model.fit(X_train, y_train[:, i*2+1])\n",
    "        \n",
    "        # Validate\n",
    "        x_pred = x_model.predict(X_test)\n",
    "        y_pred = y_model.predict(X_test)\n",
    "        \n",
    "        # Calculate error\n",
    "        x_mse = mean_squared_error(y_test[:, i*2], x_pred)\n",
    "        y_mse = mean_squared_error(y_test[:, i*2+1], y_pred)\n",
    "        \n",
    "        joint_models.append((x_model, y_model))\n",
    "        joint_errors.append((x_mse, y_mse))\n",
    "        \n",
    "        print(f\"  Joint {i+1} X MSE: {x_mse:.4f}, Y MSE: {y_mse:.4f}\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Training completed in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return joint_models, joint_errors\n",
    "\n",
    "# Evaluate and visualize results\n",
    "def evaluate_and_visualize(processed_data, joint_models, feature_scaler, num_samples=5):\n",
    "    # Choose random samples for visualization\n",
    "    sample_indices = np.random.choice(len(processed_data), min(num_samples, len(processed_data)), replace=False)\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        img = processed_data[idx]['image']\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Extract HOG features\n",
    "        hog = cv2.HOGDescriptor((128, 256), (16, 16), (8, 8), (8, 8), 9)\n",
    "        features = hog.compute(img_gray).flatten()\n",
    "        \n",
    "        # Scale features\n",
    "        features_scaled = feature_scaler.transform(features.reshape(1, -1))\n",
    "        \n",
    "        # Predict joint positions\n",
    "        predicted_joints = []\n",
    "        for x_model, y_model in joint_models:\n",
    "            x_pred = x_model.predict(features_scaled)[0]\n",
    "            y_pred = y_model.predict(features_scaled)[0]\n",
    "            predicted_joints.append((x_pred, y_pred))\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Original image with ground truth\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        for joint in processed_data[idx]['joints']:\n",
    "            if joint is not None:\n",
    "                plt.plot(joint[0], joint[1], 'go', markersize=5)\n",
    "        plt.title('Ground Truth')\n",
    "        \n",
    "        # Image with predictions\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        for joint in predicted_joints:\n",
    "            plt.plot(joint[0], joint[1], 'ro', markersize=5)\n",
    "        plt.title('Predictions')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Draw skeleton for better visualization\n",
    "        plt.figure(figsize=(8, 16))\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Draw predicted joints\n",
    "        for joint in predicted_joints:\n",
    "            plt.plot(joint[0], joint[1], 'ro', markersize=5)\n",
    "        \n",
    "        # Define skeleton connections - simplified MPII skeleton\n",
    "        # Adjust based on your joint ordering in MPII dataset\n",
    "        skeleton_pairs = [\n",
    "            (0, 1),  # head to neck\n",
    "            (1, 2),  # neck to right shoulder\n",
    "            (1, 5),  # neck to left shoulder\n",
    "            (2, 3),  # right shoulder to right elbow\n",
    "            (3, 4),  # right elbow to right wrist\n",
    "            (5, 6),  # left shoulder to left elbow\n",
    "            (6, 7),  # left elbow to left wrist\n",
    "            (1, 8),  # neck to hip\n",
    "            (8, 9),  # hip to right hip\n",
    "            (8, 12), # hip to left hip\n",
    "            (9, 10), # right hip to right knee\n",
    "            (10, 11), # right knee to right ankle\n",
    "            (12, 13), # left hip to left knee\n",
    "            (13, 14)  # left knee to left ankle\n",
    "        ]\n",
    "        \n",
    "        # Draw skeleton lines connecting joints\n",
    "        for pair in skeleton_pairs:\n",
    "            if pair[0] < len(predicted_joints) and pair[1] < len(predicted_joints):\n",
    "                plt.plot([predicted_joints[pair[0]][0], predicted_joints[pair[1]][0]],\n",
    "                         [predicted_joints[pair[0]][1], predicted_joints[pair[1]][1]], 'b-', linewidth=2)\n",
    "        \n",
    "        plt.title('Pose Skeleton')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Function to predict pose on new images\n",
    "def predict_pose(image_path, joint_models, feature_scaler):\n",
    "    # Load and preprocess image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not load image from {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Resize for consistent HOG extraction\n",
    "    img_resized = cv2.resize(img, (128, 256))\n",
    "    img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Extract HOG features\n",
    "    hog = cv2.HOGDescriptor((128, 256), (16, 16), (8, 8), (8, 8), 9)\n",
    "    features = hog.compute(img_gray).flatten()\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = feature_scaler.transform(features.reshape(1, -1))\n",
    "    \n",
    "    # Predict joint positions\n",
    "    predicted_joints = []\n",
    "    for x_model, y_model in joint_models:\n",
    "        x_pred = x_model.predict(features_scaled)[0]\n",
    "        y_pred = y_model.predict(features_scaled)[0]\n",
    "        predicted_joints.append((x_pred, y_pred))\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(8, 16))\n",
    "    plt.imshow(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Draw predicted joints\n",
    "    for joint in predicted_joints:\n",
    "        plt.plot(joint[0], joint[1], 'ro', markersize=5)\n",
    "    \n",
    "    # Draw skeleton lines connecting joints\n",
    "    skeleton_pairs = [\n",
    "        (0, 1),  # head to neck\n",
    "        (1, 2),  # neck to right shoulder\n",
    "        (1, 5),  # neck to left shoulder\n",
    "        (2, 3),  # right shoulder to right elbow\n",
    "        (3, 4),  # right elbow to right wrist\n",
    "        (5, 6),  # left shoulder to left elbow\n",
    "        (6, 7),  # left elbow to left wrist\n",
    "        (1, 8),  # neck to hip\n",
    "        (8, 9),  # hip to right hip\n",
    "        (8, 12), # hip to left hip\n",
    "        (9, 10), # right hip to right knee\n",
    "        (10, 11), # right knee to right ankle\n",
    "        (12, 13), # left hip to left knee\n",
    "        (13, 14)  # left knee to left ankle\n",
    "    ]\n",
    "    \n",
    "    for pair in skeleton_pairs:\n",
    "        if pair[0] < len(predicted_joints) and pair[1] < len(predicted_joints):\n",
    "            plt.plot([predicted_joints[pair[0]][0], predicted_joints[pair[1]][0]],\n",
    "                     [predicted_joints[pair[0]][1], predicted_joints[pair[1]][1]], 'b-', linewidth=2)\n",
    "    \n",
    "    plt.title('Pose Estimation')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_joints\n",
    "\n",
    "# Function to save models\n",
    "def save_models(joint_models, feature_scaler, filepath='hog_svm_pose_model.pkl'):\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'joint_models': joint_models,\n",
    "            'feature_scaler': feature_scaler\n",
    "        }, f)\n",
    "    print(f\"Models saved to {filepath}\")\n",
    "\n",
    "# Function to load models\n",
    "def load_models(filepath='hog_svm_pose_model.pkl'):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data['joint_models'], data['feature_scaler']\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    import pickle\n",
    "    \n",
    "    # 1. Load MPII dataset\n",
    "    print(\"Loading MPII dataset...\")\n",
    "    mpii_data = load_mpii_dataset('mpii_human_pose_v1_u12_1.mat', './') \n",
    "    \n",
    "    # Check if we got any data\n",
    "    if len(mpii_data) == 0:\n",
    "        print(\"No data loaded from MPII dataset. Check paths and file format.\")\n",
    "    else:\n",
    "        # 2. Preprocess data\n",
    "        print(\"\\nPreprocessing images...\")\n",
    "        processed_mpii = preprocess_for_hog_svm(mpii_data)\n",
    "        \n",
    "        # 3. Extract HOG features\n",
    "        print(\"\\nExtracting HOG features...\")\n",
    "        X, y = extract_hog_features(processed_mpii)\n",
    "        print(f\"Feature matrix shape: {X.shape}\")\n",
    "        print(f\"Labels matrix shape: {y.shape}\")\n",
    "        \n",
    "        # 4. Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # 5. Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # 6. Train models\n",
    "        print(\"\\nTraining SVM models...\")\n",
    "        joint_models, errors = train_joint_models(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "        \n",
    "        # 7. Save models\n",
    "        save_models(joint_models, scaler)\n",
    "        \n",
    "        # 8. Evaluate\n",
    "        print(\"\\nEvaluating models...\")\n",
    "        evaluate_and_visualize(processed_mpii, joint_models, scaler, num_samples=3)\n",
    "        \n",
    "        # 9. Test on specific image\n",
    "        print(\"\\nTesting on a new image...\")\n",
    "        test_img_path = processed_mpii[0]['original_path']  # Using first image as example\n",
    "        predict_pose(test_img_path, joint_models, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
